<project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/maven-v4_0_0.xsd">
  <modelVersion>4.0.0</modelVersion>
  <groupId>ndk</groupId>
  <artifactId>spark-test</artifactId>
  <version>0.0-SNAPSHOT</version>
  <name>Test Spark Testing</name>
  <description>A project to test the basic testing capabilities published by spark</description>
  <inceptionYear>2018</inceptionYear>

  <licenses>
    <license>
      <name>My License</name>
      <url>http://....</url>
      <distribution>repo</distribution>
    </license>
  </licenses>

  <properties>
    <maven.compiler.source>1.8</maven.compiler.source>
    <maven.compiler.target>1.8</maven.compiler.target>
    <encoding>UTF-8</encoding>
    <scala.version>2.11.8</scala.version>
    <scala.compat.version>2.11</scala.compat.version>
    <spark.version>2.4.0-SNAPSHOT</spark.version>
  </properties>

  <dependencies>
    <dependency>
      <groupId>org.scala-lang</groupId>
      <artifactId>scala-library</artifactId>
      <version>${scala.version}</version>
    </dependency>

    <!-- TODO: Figure out how to have two different produced jars, the standard one with
         both spark-core and spark-sql test dependencies, and one labeled no-sql with just
         spark-core test dependencies -->
    <!-- Spark test jars -->
    <dependency>
	    <groupId>org.apache.spark</groupId>
	    <artifactId>spark-core_${scala.compat.version}</artifactId>
	    <version>${spark.version}</version>
	    <type>test-jar</type>
    </dependency>
    <dependency>
	    <groupId>org.apache.spark</groupId>
	    <artifactId>spark-sql_${scala.compat.version}</artifactId>
	    <version>${spark.version}</version>
    </dependency>
    <dependency>
	    <groupId>org.apache.spark</groupId>
	    <artifactId>spark-catalyst_${scala.compat.version}</artifactId>
	    <version>${spark.version}</version>
    </dependency>
    <!-- Test dependencies are not transitive in Maven, so we have to manually include
         both spark-sql and spark-catalyst's test jars. -->
    <dependency>
	    <groupId>org.apache.spark</groupId>
	    <artifactId>spark-sql_${scala.compat.version}</artifactId>
	    <version>${spark.version}</version>
	    <type>test-jar</type>
    </dependency>
    <dependency>
	    <groupId>org.apache.spark</groupId>
	    <artifactId>spark-catalyst_${scala.compat.version}</artifactId>
	    <version>${spark.version}</version>
	    <type>test-jar</type>
    </dependency>

    <!-- We assume those who depend on us will depend on scalatest themselves; therefore
         we leave scalatest with test scope. -->
    <dependency>
      <groupId>org.scalatest</groupId>
      <artifactId>scalatest_${scala.compat.version}</artifactId>
      <version>3.0.4</version>
      <scope>test</scope>
    </dependency>
  </dependencies>

  <build>
    <sourceDirectory>src/main/scala</sourceDirectory>
    <testSourceDirectory>src/test/scala</testSourceDirectory>
    <plugins>
	    <!-- enable scala -->
	    <plugin>
		    <groupId>net.alchim31.maven</groupId>
		    <artifactId>scala-maven-plugin</artifactId>
		    <version>3.2.2</version>
		    <executions>
			    <execution>
				    <id>scala-test-compile-first</id>
				    <goals>
					    <goal>testCompile</goal>
				    </goals>
			    </execution>
		    </executions>
	    </plugin>
	    <!-- enable scalatest -->
	    <plugin>
		    <groupId>org.scalatest</groupId>
		    <artifactId>scalatest-maven-plugin</artifactId>
		    <version>1.0</version>
		    <configuration>
			    <reportsDirectory>${project.build.directory}/surefire-reports</reportsDirectory>
			    <junitxml>.</junitxml>
		    </configuration>
		    <executions>
			    <execution>
				    <id>test</id>
				    <goals>
					    <goal>test</goal>
				    </goals>
			    </execution>
		    </executions>
	    </plugin>
    </plugins>
  </build>
</project>
